package tokenizer

import (
	"testing"

	"github.com/samber/lo"
	"github.com/stretchr/testify/assert"
)

func TestBytesToUnicode(t *testing.T) {
	is := assert.New(t)

	// Most useful test E.V.E.R ^^
	want := map[rune]string{
		0:   "Ä€",
		1:   "Ä",
		2:   "Ä‚",
		3:   "Äƒ",
		4:   "Ä„",
		5:   "Ä…",
		6:   "Ä†",
		7:   "Ä‡",
		8:   "Äˆ",
		9:   "Ä‰",
		10:  "ÄŠ",
		11:  "Ä‹",
		12:  "ÄŒ",
		13:  "Ä",
		14:  "Ä",
		15:  "Ä",
		16:  "Ä",
		17:  "Ä‘",
		18:  "Ä’",
		19:  "Ä“",
		20:  "Ä”",
		21:  "Ä•",
		22:  "Ä–",
		23:  "Ä—",
		24:  "Ä˜",
		25:  "Ä™",
		26:  "Äš",
		27:  "Ä›",
		28:  "Äœ",
		29:  "Ä",
		30:  "Ä",
		31:  "ÄŸ",
		32:  "Ä ",
		33:  "!",
		34:  "\"",
		35:  "#",
		36:  "$",
		37:  "%",
		38:  "&",
		39:  "'",
		40:  "(",
		41:  ")",
		42:  "*",
		43:  "+",
		44:  ",",
		45:  "-",
		46:  ".",
		47:  "/",
		48:  "0",
		49:  "1",
		50:  "2",
		51:  "3",
		52:  "4",
		53:  "5",
		54:  "6",
		55:  "7",
		56:  "8",
		57:  "9",
		58:  ":",
		59:  ";",
		60:  "<",
		61:  "=",
		62:  ">",
		63:  "?",
		64:  "@",
		65:  "A",
		66:  "B",
		67:  "C",
		68:  "D",
		69:  "E",
		70:  "F",
		71:  "G",
		72:  "H",
		73:  "I",
		74:  "J",
		75:  "K",
		76:  "L",
		77:  "M",
		78:  "N",
		79:  "O",
		80:  "P",
		81:  "Q",
		82:  "R",
		83:  "S",
		84:  "T",
		85:  "U",
		86:  "V",
		87:  "W",
		88:  "X",
		89:  "Y",
		90:  "Z",
		91:  "[",
		92:  "\\",
		93:  "]",
		94:  "^",
		95:  "_",
		96:  "`",
		97:  "a",
		98:  "b",
		99:  "c",
		100: "d",
		101: "e",
		102: "f",
		103: "g",
		104: "h",
		105: "i",
		106: "j",
		107: "k",
		108: "l",
		109: "m",
		110: "n",
		111: "o",
		112: "p",
		113: "q",
		114: "r",
		115: "s",
		116: "t",
		117: "u",
		118: "v",
		119: "w",
		120: "x",
		121: "y",
		122: "z",
		123: "{",
		124: "|",
		125: "}",
		126: "~",
		127: "Ä¡",
		128: "Ä¢",
		129: "Ä£",
		130: "Ä¤",
		131: "Ä¥",
		132: "Ä¦",
		133: "Ä§",
		134: "Ä¨",
		135: "Ä©",
		136: "Äª",
		137: "Ä«",
		138: "Ä¬",
		139: "Ä­",
		140: "Ä®",
		141: "Ä¯",
		142: "Ä°",
		143: "Ä±",
		144: "Ä²",
		145: "Ä³",
		146: "Ä´",
		147: "Äµ",
		148: "Ä¶",
		149: "Ä·",
		150: "Ä¸",
		151: "Ä¹",
		152: "Äº",
		153: "Ä»",
		154: "Ä¼",
		155: "Ä½",
		156: "Ä¾",
		157: "Ä¿",
		158: "Å€",
		159: "Å",
		160: "Å‚",
		161: "Â¡",
		162: "Â¢",
		163: "Â£",
		164: "Â¤",
		165: "Â¥",
		166: "Â¦",
		167: "Â§",
		168: "Â¨",
		169: "Â©",
		170: "Âª",
		171: "Â«",
		172: "Â¬",
		173: "Åƒ",
		174: "Â®",
		175: "Â¯",
		176: "Â°",
		177: "Â±",
		178: "Â²",
		179: "Â³",
		180: "Â´",
		181: "Âµ",
		182: "Â¶",
		183: "Â·",
		184: "Â¸",
		185: "Â¹",
		186: "Âº",
		187: "Â»",
		188: "Â¼",
		189: "Â½",
		190: "Â¾",
		191: "Â¿",
		192: "Ã€",
		193: "Ã",
		194: "Ã‚",
		195: "Ãƒ",
		196: "Ã„",
		197: "Ã…",
		198: "Ã†",
		199: "Ã‡",
		200: "Ãˆ",
		201: "Ã‰",
		202: "ÃŠ",
		203: "Ã‹",
		204: "ÃŒ",
		205: "Ã",
		206: "Ã",
		207: "Ã",
		208: "Ã",
		209: "Ã‘",
		210: "Ã’",
		211: "Ã“",
		212: "Ã”",
		213: "Ã•",
		214: "Ã–",
		215: "Ã—",
		216: "Ã˜",
		217: "Ã™",
		218: "Ãš",
		219: "Ã›",
		220: "Ãœ",
		221: "Ã",
		222: "Ã",
		223: "ÃŸ",
		224: "Ã ",
		225: "Ã¡",
		226: "Ã¢",
		227: "Ã£",
		228: "Ã¤",
		229: "Ã¥",
		230: "Ã¦",
		231: "Ã§",
		232: "Ã¨",
		233: "Ã©",
		234: "Ãª",
		235: "Ã«",
		236: "Ã¬",
		237: "Ã­",
		238: "Ã®",
		239: "Ã¯",
		240: "Ã°",
		241: "Ã±",
		242: "Ã²",
		243: "Ã³",
		244: "Ã´",
		245: "Ãµ",
		246: "Ã¶",
		247: "Ã·",
		248: "Ã¸",
		249: "Ã¹",
		250: "Ãº",
		251: "Ã»",
		252: "Ã¼",
		253: "Ã½",
		254: "Ã¾",
		255: "Ã¿",
	}

	got := bytesToUnicode()
	is.EqualValues(want, got)
}

func TestNewEncoder_bpeRank(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	is.EqualValues(49830, encoder.bpeRank[lo.T2("c", "rim")])
	is.EqualValues(49880, encoder.bpeRank[lo.T2("Ä dispens", "ary")])
	is.EqualValues(49905, encoder.bpeRank[lo.T2("Ä Am", "p")])
}

func TestNewEncoder_encoder(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	is.EqualValues(50225, encoder.encoder["Ä reclaimed"])
	is.EqualValues(50145, encoder.encoder["headers"])
	is.EqualValues(50256, encoder.encoder["<|endoftext|>"])
}

func TestNewEncoder_decoder(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	is.EqualValues("Ä reclaimed", encoder.decoder[50225])
	is.EqualValues("headers", encoder.decoder[50145])
	is.EqualValues("<|endoftext|>", encoder.decoder[50256])
}

func TestNewEncoder_splitToken(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	want := []string{
		"hello",
		" ğŸ‘‹",
		" world",
		" ğŸŒ",
		" This",
		" is",
		" a",
		" long",
		" string",
		" to",
		" test",
		" whether",
		" or",
		" not",
		" the",
		" emoji",
		" issue",
		" was",
		" fixed",
		"!",
	}

	got, err := encoder.splitToken("hello ğŸ‘‹ world ğŸŒ This is a long string to test whether or not the emoji issue was fixed!")
	is.EqualValues(want, got)
	is.Nil(err)
}

func TestGetPairs(t *testing.T) {
	is := assert.New(t)

	words := [][]string{
		{"h", "e", "l", "l", "o"},
		{"he", "l", "l", "o"},
		{"hel", "l", "o"},
		{"hell", "o"},
		{"hello"},
		{"Ä ", "Ã°", "Å", "Ä³", "Ä­"},
		{"Ä ", "w", "o", "r", "l", "d"},
		{"Ä ", "Ã°", "Å", "Ä®", "Ä¯"},
		{"Ä ", "T", "h", "i", "s"},
		{"Ä ", "i", "s"},
		{"Ä ", "a"},
		{"Ä ", "l", "o", "n", "g"},
		{"Ä ", "s", "t", "r", "i", "n", "g"},
		{"Ä ", "t", "o"},
		{"Ä ", "t", "e", "s", "t"},
		{"Ä ", "w", "h", "e", "t", "h", "e", "r"},
		{"Ä ", "o", "r"},
		{"Ä ", "n", "o", "t"},
		{"Ä ", "t", "h", "e"},
		{"Ä ", "e", "m", "o", "j", "i"},
		{"Ä ", "i", "s", "s", "u", "e"},
		{"Ä ", "w", "a", "s"},
		{"Ä ", "f", "i", "x", "e", "d"},
		{"!"},
	}

	wants := [][]lo.Tuple2[string, string]{
		{lo.T2("h", "e"), lo.T2("e", "l"), lo.T2("l", "l"), lo.T2("l", "o")},
		{lo.T2("he", "l"), lo.T2("l", "l"), lo.T2("l", "o")},
		{lo.T2("hel", "l"), lo.T2("l", "o")},
		{lo.T2("hell", "o")},
		{},
		{lo.T2("Ä ", "Ã°"), lo.T2("Ã°", "Å"), lo.T2("Å", "Ä³"), lo.T2("Ä³", "Ä­")},
		{lo.T2("Ä ", "w"), lo.T2("w", "o"), lo.T2("o", "r"), lo.T2("r", "l"), lo.T2("l", "d")},
		{lo.T2("Ä ", "Ã°"), lo.T2("Ã°", "Å"), lo.T2("Å", "Ä®"), lo.T2("Ä®", "Ä¯")},
		{lo.T2("Ä ", "T"), lo.T2("T", "h"), lo.T2("h", "i"), lo.T2("i", "s")},
		{lo.T2("Ä ", "i"), lo.T2("i", "s")},
		{lo.T2("Ä ", "a")},
		{lo.T2("Ä ", "l"), lo.T2("l", "o"), lo.T2("o", "n"), lo.T2("n", "g")},
		{lo.T2("Ä ", "s"), lo.T2("s", "t"), lo.T2("t", "r"), lo.T2("r", "i"), lo.T2("i", "n"), lo.T2("n", "g")},
		{lo.T2("Ä ", "t"), lo.T2("t", "o")},
		{lo.T2("Ä ", "t"), lo.T2("t", "e"), lo.T2("e", "s"), lo.T2("s", "t")},
		{lo.T2("Ä ", "w"), lo.T2("w", "h"), lo.T2("h", "e"), lo.T2("e", "t"), lo.T2("t", "h"), lo.T2("e", "r")},
		{lo.T2("Ä ", "o"), lo.T2("o", "r")},
		{lo.T2("Ä ", "n"), lo.T2("n", "o"), lo.T2("o", "t")},
		{lo.T2("Ä ", "t"), lo.T2("t", "h"), lo.T2("h", "e")},
		{lo.T2("Ä ", "e"), lo.T2("e", "m"), lo.T2("m", "o"), lo.T2("o", "j"), lo.T2("j", "i")},
		{lo.T2("Ä ", "i"), lo.T2("i", "s"), lo.T2("s", "s"), lo.T2("s", "u"), lo.T2("u", "e")},
		{lo.T2("Ä ", "w"), lo.T2("w", "a"), lo.T2("a", "s")},
		{lo.T2("Ä ", "f"), lo.T2("f", "i"), lo.T2("i", "x"), lo.T2("x", "e"), lo.T2("e", "d")},
		{},
	}

	for i := range words {
		want := wants[i]
		got := getPairs(words[i])
		is.EqualValues(want, got, i)
	}

	got := getPairs([]string{"hello"})
	is.EqualValues([]lo.Tuple2[string, string]{}, got)
}

func TestNewEncoder_bpe(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	cases := []lo.Tuple2[string, string]{
		lo.T2("hello", "hello"),
		lo.T2("Ä Ã°ÅÄ³Ä­", "Ä Ã°ÅÄ³ Ä­"),
		lo.T2("Ä world", "Ä world"),
		lo.T2("Ä Ã°ÅÄ®Ä¯", "Ä Ã°Å Ä® Ä¯"),
		lo.T2("Ä This", "Ä This"),
		lo.T2("Ä is", "Ä is"),
		lo.T2("Ä a", "Ä a"),
		lo.T2("Ä long", "Ä long"),
		lo.T2("Ä string", "Ä string"),
		lo.T2("Ä to", "Ä to"),
		lo.T2("Ä test", "Ä test"),
		lo.T2("Ä whether", "Ä whether"),
		lo.T2("Ä or", "Ä or"),
		lo.T2("Ä not", "Ä not"),
		lo.T2("Ä the", "Ä the"),
		lo.T2("Ä emoji", "Ä emoji"),
		lo.T2("Ä issue", "Ä issue"),
		lo.T2("Ä was", "Ä was"),
		lo.T2("Ä fixed", "Ä fixed"),
	}

	for _, c := range cases {
		got := encoder.bpe(c.A)
		want := c.B
		is.EqualValues(want, got)
	}
}

func TestNewEncoder_encode(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	want := []int{31373, 995, 770, 318, 257, 890, 4731, 284, 1332, 1771, 393, 407, 262, 44805, 2071, 373, 5969, 0}
	got, err := encoder.Encode("hello world This is a long string to test whether or not the emoji issue was fixed!")
	is.EqualValues(want, got)
	is.Nil(err)

	// @TODO
	// want = []int{31373, 50169, 233, 995, 12520, 234, 235, 770, 318, 257, 890, 4731, 284, 1332, 1771, 393, 407, 262, 44805, 2071, 373, 5969, 0}
	// got, err = encoder.Encode("hello ğŸ‘‹ world ğŸŒ This is a long string to test whether or not the emoji issue was fixed!")
	// is.EqualValues(want, got)
	// is.Nil(err)
}

func TestNewEncoder_decode(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	want := "hello world This is a long string to test whether or not the emoji issue was fixed!"
	got := encoder.Decode([]int{31373, 995, 770, 318, 257, 890, 4731, 284, 1332, 1771, 393, 407, 262, 44805, 2071, 373, 5969, 0})
	is.EqualValues(want, got)

	// @TODO
	// want = "hello ğŸ‘‹ world ğŸŒ This is a long string to test whether or not the emoji issue was fixed!"
	// got = encoder.Decode([]int{31373, 50169, 233, 995, 12520, 234, 235, 770, 318, 257, 890, 4731, 284, 1332, 1771, 393, 407, 262, 44805, 2071, 373, 5969, 0})
	// is.EqualValues(want, got)
}

func TestNewEncoder_e2e(t *testing.T) {
	is := assert.New(t)

	encoder, err := NewEncoder()
	is.Nil(err)

	cases := []lo.Tuple2[string, []int]{
		// lo.T2("", []int{}),	// @TODO
		lo.T2(" ", []int{220}),
		lo.T2("\t", []int{197}),
		lo.T2("This is some text", []int{1212, 318, 617, 2420}),
		lo.T2("indivisible", []int{521, 452, 12843}),
		// lo.T2("hello ğŸ‘‹ world ğŸŒ", []int{31373, 50169, 233, 995, 12520, 234, 235}),	// @TODO
	}

	for _, c := range cases {
		encoded, err := encoder.Encode(c.A)
		is.Nil(err)
		is.EqualValues(c.B, encoded, c.A)

		result := encoder.Decode(encoded)
		is.EqualValues(c.A, result, c.A)
	}
}
